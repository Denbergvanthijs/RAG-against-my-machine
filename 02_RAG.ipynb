{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG against my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "# Embedding model for retrieval\n",
    "# embed_id = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# embed_id = \"sentence-transformers/all-MiniLM-L6-v2\"  # Faster model\n",
    "embed_id = \"paraphrase-multilingual-MiniLM-L12-v2\"  # Multilingual model, including Dutch\n",
    "embed_model_kwargs = {\"device\": \"cpu\"}\n",
    "embed_encode_kwargs = {\"normalize_embeddings\": False}\n",
    "\n",
    "# Vector store\n",
    "chroma_db = \"./chroma_db\"\n",
    "vectorstore_search_kwargs = {\"k\": 6}\n",
    "\n",
    "# LLM model for generation\n",
    "# llm_id = \"Rijgersberg/GEITje-7B\"\n",
    "# llm_id = \"GroNLP/bert-base-dutch-cased\"\n",
    "# llm_id = \"./ov_model_dir\"\n",
    "llm_id = \"./GEITje-7B-chat-v2\"\n",
    "llm_pipeline_kwargs = {\"max_new_tokens\": 100, \"return_full_text\": False}  # TODO: extend with more generation parameters\n",
    "llm_model_kwargs = {\"ov_config\": {\"KV_CACHE_PRECISION\": \"u8\",\n",
    "                                  \"DYNAMIC_QUANTIZATION_GROUP_SIZE\": \"32\",\n",
    "                                  \"PERFORMANCE_HINT\": \"LATENCY\",\n",
    "                                  \"NUM_STREAMS\": \"1\",\n",
    "                                  \"CACHE_DIR\": \"\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model for retrieval\n",
    "embed_model = HuggingFaceEmbeddings(model_name=embed_id, model_kwargs=embed_model_kwargs, encode_kwargs=embed_encode_kwargs)\n",
    "\n",
    "# Create the vectorstore, load from disk\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embed_model)\n",
    "\n",
    "# Convert vectorstore to retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs=vectorstore_search_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Welke kerncentrale is recent buiten bedrijf gesteld?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 retrieved docs\n",
      "Contents:\n",
      "Doc 0: title: Enige Litouwse kerncentrale dicht\n",
      "content: De enige kerncentrale van Litouwen is oudjaarsavond om 23.00 uur buiten gebruik gesteld. Dat verliep zonder problemen, aldus de directeur. Litouwen be\n",
      "Doc 1: Olympische organisatie, heeft 650 bedrijven gevraagd om het vervoer van werknemers terug te dringen, maar daarop is nog niet veel respons gekomen. Het is business as usual voor veel bedrijven. Andere \n",
      "Doc 2: Skidmore, Owens en Meril (SOM) dat gespecialiseerd is in wolkenkrabbers. Zij ontwierpen onder andere de Sears Tower in Chicago en de Russia Tower in Moskou. Woestijnbloem Het ontwerp van de toren is g\n",
      "Doc 3: content: De luchthaven Schiphol koopt nog eens zestig bodyscanners. Er staan er nu zestien, maar de controles worden sterk uitgebreid. De eerste twintig nieuwe scanners staan er volgende week. De aanl\n",
      "Doc 4: Het betrof echter slechts een mondeling akkoord. Toen DSB failliet ging en curatoren het bewind overnamen, erkenden zij de regeling niet. Oproep Stichting Probleemhypotheken is voortgekomen uit de sti\n",
      "Doc 5: title: FNV-actie tegen uitbuiting Polen\n",
      "content: FNV Bondgenoten heeft vanmorgen bij de Groningse vleesverwerker Beusmeat in Leek actie gevoerd tegen de uitbuiting van 150 Poolse uitzendkrachten. De b\n"
     ]
    }
   ],
   "source": [
    "# Retrieve documents as example\n",
    "retrieved_docs = retriever.invoke(question)\n",
    "\n",
    "print(f\"{len(retrieved_docs)} retrieved docs\")\n",
    "print(\"Contents:\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"Doc {i}: {doc.page_content[:200]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='<s> Je bent een assistent voor het beantwoorden van vragen. Gebruik de volgende stukjes opgehaalde context om de vraag te beantwoorden. Als je het antwoord niet weet, zeg dan gewoon dat je het niet weet. Gebruik maximaal drie zinnen en houd het antwoord beknopt. </s> Vraag: filler question \\nContext: filler context \\nAntwoord: ')]\n"
     ]
    }
   ],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [(\"human\", \"Je bent een assistent voor het beantwoorden van vragen. Gebruik de volgende stukjes opgehaalde context om de vraag te beantwoorden. Als je het antwoord niet weet, zeg dan gewoon dat je het niet weet. Gebruik maximaal drie zinnen en houd het antwoord beknopt.\\nVraag: {question} \\nContext: {context} \\nAntwoord:\")])\n",
    "\n",
    "# Input prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"<s> Je bent een assistent voor het beantwoorden van vragen. Gebruik de volgende stukjes opgehaalde context om de vraag te beantwoorden. Als je het antwoord niet weet, zeg dan gewoon dat je het niet weet. Gebruik maximaal drie zinnen en houd het antwoord beknopt. </s> Vraag: {question} \\nContext: {context} \\nAntwoord: \")])\n",
    "\n",
    "example_messages = prompt.invoke({\"context\": \"filler context\", \"question\": \"filler question\"}).to_messages()\n",
    "print(example_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\denbe\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\utils\\import_utils.py:519: FutureWarning: `is_torch_tpu_available` is deprecated and will be removed in 4.41.0. Please use the `is_torch_xla_available` instead.\n",
      "  warnings.warn(\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "# Create the LLM used for generation\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=llm_id,\n",
    "                                        task=\"text-generation\",\n",
    "                                        backend=\"openvino\",\n",
    "                                        model_kwargs=llm_model_kwargs,\n",
    "                                        pipeline_kwargs=llm_pipeline_kwargs)  # TODO: Add device_map=\"auto\" once device= is removed\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "             | prompt\n",
    "             | llm\n",
    "             | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welke kerncentrale is recent buiten bedrijf gesteld?\n"
     ]
    }
   ],
   "source": [
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "De FNV-bond heeft vanmorgen bij de Groningse vleesverwerker Beusmeat in Leek actie gevoerd tegen de uitbuiting van 150 Poolse uitzendkrachten. De bond deelde bij de poort pamfletten uit om de Polen te steunen. Volgens de bond krijgen ze minder dan het minimumloon en hebben ze een 50\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.invoke(question)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
